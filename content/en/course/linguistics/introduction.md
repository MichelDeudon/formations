---
title: Introduction
date: '2021-01-01'
type: book
weight: 20
---

Motivate language studies.

<!--more-->

{{< icon name="clock" pack="fas" >}} 1h20 introductory course

## Why study languages? 

{{< youtube -R6YMWb0vUA >}}

<br> 
Kate Jefferey is a professor in neuroscience at UCL, London, and scientific lead at Exctinction Rebellion. In her inspiring talk on [the psychology of climate inaction](https://www.youtube.com/watch?v=-R6YMWb0vUA&ab_channel=UCLMindsLunchHourLectures), the tragedy of commons has no rational solution. Language, as a way to communicate with each other and collaborate, has a key role to play in the way we understand the past, envision the future, and deal with the present. <i>With language we have gone further than any species on Earth, we went on the Moon</i>. What if we all started to learn a language with empathy and used language to fix some of our biggest problems ?

<br>
The idea that mankind is a social animal is found in many books. As opposed to the classic theory in economics, in which human beings act rationally, Dan Ariely in his book [Predictibly Irrational](https://predictablyirrational.com/) invites us to question the way Human beings take decisions and make choices. Here again, language has a fundamental role in understanding the hidden forces that shape our decisions. We need to embrace language and our irrationality to imaginate and co-create a better tomorrow.

<b>Computational linguistics</b> is an interdisciplinary field that deals with languages, psychology, social sciences, statistics, computer science, artificial intelligence and more. It has gained in popularity in the last decade with the release of open source datasets, libraries, courses, etc. Models have increased in accuracy and on other metrics, on different benchmarks (e.g., translation). However, this increase in performance comes with a drastic increase in complexity and ressources required (data, hardware, energy). A new paradigm in AI and computational lingustics is needed.

## Why study frugal innovation?

> <i>All models are wrong but some are better than others</i> - A professor in physics

Models in data science have drastically increased in complexity in the last 10 years, at the advantage of cloud providers like Google, Microsoft and Amazon üå•Ô∏è. First in computer vision in the 2012s, then gradually in linguistics since 2014 with word vectors, document embeddings and attention models.

BERT, RoBERT, CamemBERT üßÄ are models with a quadratric complexity. AI conferences are dominated by players that own platforms running these models as a service. Why solve a problem in 5 minutes when you can charge more for hours? It's called a conflict of interest, it may sound silly but that‚Äôs how the field became toxic, from expired cheese ü§¢ That‚Äôs where the money comes from and not where the value lies üíõ I personnaly struggled getting papers published and working in the field.

> <i>Training a single AI model can emit as much carbon as five cars in their lifetimes (...) The most costly model, BERT, has a carbon footprint of roughly 1,400 pounds of carbon dioxide equivalent, close to a round-trip trans-America flight for one person.</i> [Technology Review, 2019](https://www.technologyreview.com/2019/06/06/239031/training-a-single-ai-model-can-emit-as-much-carbon-as-five-cars-in-their-lifetimes/). 

In the last conferences I‚Äôve attended, most speakers present variants of BERT üöÄ, known to emit as much carbon emissions as a transatlantic flight ‚úàÔ∏è everytime it is trained (for comparison, the Human brain only uses 40 Watt, the equivalent of a light bulb).  Decision making systems lack <b>diversity</b> (1+1 = 1). Conflicts of interest set us further apart from our common goals like building an <b>inclusive society</b> (1+1 = 3) or <b>low carbon economy</b> ü¶ì

In addition, the way AI is done in big labs, at Google, Facebook, Microsoft or Amazon, is not appropriate for many entrepreneurs or researchers, working on new problems or with non profits. Indeed, entrepreneurs or non profits usually have few ressources (human, financial, tech). They don't have HUGE massive dataset for supervised learning or cheap labour for annotating data, but messy data and domain knowledge. Unethical practices (cheap labour, AWS Turk Youtuber moderators, suicides, PhD students, toxic pressure) are not necessarily alined with their values.

Finally, as opposed to popularised ideas in the field, there is no such things as a universal language model trained on one language (lol). Computers surpassing Humans on computer vision tasks, ok. On linguistics tasks, it doesn't make sense to say a computer speaks better than a Human. Let it speak alone and the idea of language disappears. There's a lack of diversity in the field, deep learning only uses a fraction of tools available.

We are at a crossroad in the way AI, NLP and computational linguistics are taught. While big players will continue building more powerful models, we will focus on building useful models first and attempt to democratize the access to computational linguistics to empower creators, entrepreneurs and researchers. We will lay the scientific foundations for computational linguistics, and will not explore Artificial General Intelligence, Large Language Model (LLM), unless our simpler models don't work well enough to start. By reversing the trend set by big players, frugal innovation can get us closer to build an inclusive society and low carbon economy. I‚Äôd like to share learnings with a broad audience of entrepreneurs and researchers to address societal and environmental issues.

Note: There's room to create value. We‚Äôre talking about thousands of gigatons of carbon emissions. And since a lot of the early stage investments for startups come from public organisations in Europe, it seems legit to make sure these public investments don‚Äôt put citizens‚Äô rights and freedom at risk, right? (the news remind us how wrong things can go).

## Applications & audience

- Education, language learning (Duolingo)
- Human rights, diversity & inclusion, regulatory, media & political feedback
- Food, music, dna‚Ä¶

## Course outline 

The course will explore different use cases and tested models to empower creators through illustrated examples:

- Regulatory feedback, media & politics
- Online harassment, diversity & inclusion
- Anti money laundering & modern slavery
- Food, music or dna as a language
- And more modern examples

## Quiz

{{< spoiler text="How many languages are spoken in the world today?" >}}
More than 7000 languages are spoken today, but just 23 languages account for more than half the world's population. Data science, NLP and AI research is majoritarily done in English, introducing in a bias in the way we approach computational linguistics.
{{< /spoiler >}}

{{< spoiler text="True or False, BERT, has a carbon footprint close to a round-trip trans-America flight for one person.?" >}}
True, according to [Technology Review, 2019.](https://www.technologyreview.com/2019/06/06/239031/training-a-single-ai-model-can-emit-as-much-carbon-as-five-cars-in-their-lifetimes/).
{{< /spoiler >}}
