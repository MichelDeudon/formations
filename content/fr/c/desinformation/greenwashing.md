---
title: Rep√©rer le greenwashing et les conflits d‚Äôint√©r√™ts
date: '2023-02-24'
type: book
weight: 30
tags:
  - √©nergie
  - climat
  - d√©sinformation
---

Quel est le but des climatosceptiques? Que d√©fendent-ils? √âtude de cas √† travers les mod√®les LLaMA et ChatGPT.

<!--more-->

## La d√©sinformation sert √† d√©tourner l‚Äôattention de l‚Äôurgence √©cologique‚Ä¶

Le but de la d√©sinformation comme [business](https://www.bfmtv.com/tech/intelligence-artificielle/le-patron-de-l-entreprise-a-l-origine-de-chat-gpt-a-un-peu-peur-de-chat-gpt_AV-202303210270.html) est de d√©tourner l‚Äôattention et influencer les d√©cisions, par exemple dans quoi [investir](https://www.bpifrance.fr/nos-actualites/rencontres-economiques-daix-en-provence-un-regard-sur-le-monde-demain), de quoi [d√©battre](https://www.bfmtv.com/tech/intelligence-artificielle/pour-la-premiere-fois-l-assemblee-nationale-va-debattre-d-un-amendement-redige-par-chat-gpt_AV-202303210310.html), etc. Lorsqu‚Äôelle est toxique et virale, elle g√©n√®re plus de clics (Click Through Rate en anglais) et appelle √† plus de deeptech...

Ainsi, les d√©veloppements d'IA pendant l'automne hiver 2022/2023 - [Galactica 120B](https://huggingface.co/facebook/galactica-120b), ChatGPT3, LLaMA 65B, ChatGPT4 - et la d√©sinformation a permis de d√©tourner l'attention des CEO au [Forum √âconomique Mondial](https://www.reuters.com/technology/davos-2023-ceos-buzz-about-chatgpt-style-ai-world-economic-forum-2023-01-17/) pour investir dans l'armement plut√¥t que l'√©cologie, la jeunesse... au profit de HuggingFace, les GAFAMs, NVIDIA, etc.

En mars 2023, TF1 parle de menaces de l'IA sur les emplois, de risques des voitures autonomes... l'√©cologie et la jeunesse ne sont pas mentionn√©s.
Le [MIT](https://www.technologyreview.com/2019/02/14/137426/an-ai-tool-auto-generates-fake-news-bogus-tweets-and-plenty-of-gibberish/) alertait pourtant du risque en 2019 qu'IA une qui √©crit une prose convaincante risquerait de produire en masse de fausses nouvelles, faisant r√©f√©rence √† ChatGPT2. Cela n'a emp√™ch√© les investissments de se multiplier dans la d√©sinformation, la consommation √©nerg√©tique (x1000 en 4 ans) et la g√©n√©ration de fausses nouvelles.

### Ressources pour lutter contre le greenwashing
- Le guide anti greenwashing de [Pour un R√©veil Ecologique](https://pour-un-reveil-ecologique.org/fr/les-entreprises-nous-repondent/#guide-anti-greenwashing)
- L'outil en ligne anti greenwashing de l'[ADEME](https://communication-responsable.ademe.fr/antigreenwashing)

## [Pr√©sentation de LLaMA : un mod√®le de langage fondamental de 65 milliards de param√®tres](https://ai.facebook.com/blog/large-language-model-llama-meta-ai/)
{{< icon name="calendar" pack="fas" >}} F√©v 2023. Le blog de Meta AI / FAIR Paris est une {{<hl>}}perle de greenwashing{{</hl>}}.

Dans le cadre de l'engagement de Meta en faveur de la science ouverte, nous publions aujourd'hui LLaMA (Large Language Model Meta AI), un mod√®le de langage fondamental √† l‚Äô√©tat de l‚Äôart con√ßu pour aider les chercheurs √† faire progresser leurs travaux dans ce sous-domaine de l'IA. {{<hl>}}Des mod√®les <b>plus petits</b> et plus performants tels que LLaMA{{</hl>}} permettent √† d'autres membres de la communaut√© de recherche qui n'ont pas acc√®s √† de grandes quantit√©s d'infrastructures d'√©tudier ces mod√®les, d√©mocratisant davantage l'acc√®s dans ce domaine important et en √©volution rapide.

{{<hl>}}L'entra√Ænement de mod√®les fondamentaux <b>plus petits</b> comme LLaMA est souhaitable{{</hl>}} dans le champ des large language model, car {{<hl>}}√ßa n√©cessite beaucoup <b>moins de puissance de calcul et de ressources</b>{{</hl>}} pour tester de nouvelles approches, valider le travail des autres et explorer de nouveaux cas d'utilisation. Les mod√®les fondamentaux sont entra√Æn√©s sur un vaste ensemble de donn√©es non √©tiquet√©es, ce qui les rend id√©aux pour √™tre ajust√© √† une vari√©t√© de t√¢ches. Nous rendons LLaMA disponible en plusieurs tailles (param√®tres 7B, 13B, 33B et 65B) et partageons √©galement une carte du mod√®le LLaMA qui d√©taille comment nous avons construit le mod√®le conform√©ment √† notre approche des {{<hl>}}<b>pratiques d'IA responsable</b>{{</hl>}}.

{{< figure src="meta-paper-hours-gpu.png" caption="Empreinte carbone de diff√©rents mod√®les entrain√©s dans le m√™me centre de donn√©es, de l'article LLaMA sur [Arxiv](https://arxiv.org/abs/2302.13971) (section 6 Empreinte carbone).">}}

{{< callout warning >}}
<i>L'entra√Ænement de nos mod√®les a consomm√© une quantit√© massive d'√©nergie, responsable de l'√©mission de dioxyde de carbone.</i> (section 6 Empreinte carbone). <i>Nous pr√©voyons de publier √† l'avenir des mod√®les plus grands, entrain√©s sur des corpus plus importants</i> (section 8 Conclusion). [Arxiv](https://arxiv.org/abs/2302.13971).
{{< /callout >}}

{{< callout note >}}
Aucune communication n'est faite sur [le blog](https://ai.facebook.com/blog/large-language-model-llama-meta-ai/) de Meta AI Research, sur les [r√©seaux sociaux](https://www.linkedin.com/posts/yann-lecun_github-facebookresearchllama-inference-activity-7034956639526952960-B1-d?trk=public_profile_like_view) ou sur [Github](https://github.com/facebookresearch/llama/blob/1076b9c51c77ad06e9d7ba8a4c6df775741732 ) concernant l'empreinte carbone record, l'impact environnemental et le financement du mod√®le LLaMA.
{{< /callout >}}

{{<hl>}}Des mod√®les <b>plus petits</b>{{</hl>}} entra√Æn√©s sur plus de jetons - qui sont des morceaux de mots - sont {{<hl>}}<b>plus faciles</b> √† r√©entra√Æner et affiner{{</hl>}} pour des cas d'utilisation potentiels et sp√©cifiques de produits. Nous avons entra√Æn√© LLaMA 65B et LLaMA 33B sur 1,4 trilliard de jetons. Notre {{<hl>}}<b>plus petit</b> mod√®le{{</hl>}}, LLaMA 7B, est form√© sur un trilliard de jetons‚Ä¶

{{< callout note >}}
En r√©alit√© on change d‚Äô√©chelle. Millions, milliards, trilliards... C‚Äôest x1000 en complexit√© en 4 ans.
{{< /callout >}}

Il reste encore des recherches √† faire pour traiter les risques de biais, de commentaires toxiques et d'hallucinations dans les grands mod√®les de langage. Comme d'autres mod√®les, LLaMA partage ces d√©fis... Nous fournissons √©galement dans l'article un ensemble d'√©valuations sur les biais et la toxicit√© du mod√®le pour montrer les limites du mod√®le et pour soutenir la poursuite des recherches dans ce domaine crucial.

{{<hl>}}Pour maintenir l'<b>int√©grit√©</b> et pr√©venir les <b>abus</b>{{</hl>}}, nous publions notre mod√®le sous une licence non commerciale ax√©e sur les cas d'utilisation de la recherche. L'acc√®s au mod√®le sera accord√© au cas par cas aux chercheurs universitaires; ceux affili√©s √† des organisations du gouvernement, de la soci√©t√© civile et du milieu universitaire; et les laboratoires de recherche de l'industrie √† travers le monde...

{{< callout warning >}}
08 mars 2023. [Fuite du mod√®le](https://www.01net.com/actualites/fuite-meta-alternative-chatgpt-meta-partagee-forum.html). Int√©grit√© et pr√©vention des abus? Fausses nouvelles et mod√®le √©conomique?
{{< /callout >}}

## [Consid√©rations √©thiques sur Github](https://github.com/facebookresearch/llama/blob/1076b9c51c77ad06e9d7ba8a4c6df775741732bd/MODEL_CARD.md)
- Organisation d√©veloppant le mod√®le: L'√©quipe FAIR de Meta AI.
- Date du mod√®le: LLaMA a √©t√© entra√Æn√© entre d√©cembre 2022 et f√©vrier 2023.
- Version du mod√®le: Il s'agit de la version 1 du mod√®le.
- Donn√©es: Les donn√©es utilis√©es pour entra√Æner le mod√®le sont collect√©es √† partir de diverses sources, principalement du Web. En tant que tel, il contient un contenu offensant, pr√©judiciable et biais√©. Nous nous attendons √† ce que le mod√®le pr√©sente de tels biais.
- Risques et pr√©judices: Les risques et pr√©judices des grands mod√®les linguistiques incluent la g√©n√©ration de contenu nuisible, offensant ou biais√©. Ces mod√®les sont souvent susceptibles de g√©n√©rer des informations incorrectes. Nous ne nous attendons pas √† ce que notre mod√®le soit une exception √† cet √©gard.
- Cas d'utilisation: LLaMA est un mod√®le fondamental et, en tant que tel, il ne doit pas √™tre utilis√© pour des applications sans une enqu√™te plus approfondie et une att√©nuation des risques. Ces risques et cas d'utilisation potentiellement dangereux incluent, mais sans s'y limiter : la <b>g√©n√©ration de fausses informations</b> et la <b>g√©n√©ration de contenu nuisible, biais√© ou offensant</b>.

### üíß Crise climatique
- 15-02 <b style="color:red;">CNRS</b>. Climatosceptiques: sur Twitter, enqu√™te sur les mercenaires de l‚Äôintox [cnrs.fr](https://lejournal.cnrs.fr/articles/climatosceptiques-sur-twitter-enquete-sur-les-mercenaires-de-lintox) [Le Monde](https://www.lemonde.fr/planete/article/2023/02/13/la-france-fait-face-a-un-fort-regain-de-climatoscepticisme-sur-twitter_6161691_3244.html) @[Audrey Garric](https://twitter.com/audreygarric/status/1625416947729944579?cxt=HHwWhsC-1cSG0o4tAAAA).
- 31-12 (2022) <b style="color:blue;">Emmanuel Macron</b> <i>Qui aurait pu pr√©dire la crise climatique?</i> [archive INA](https://www.youtube.com/watch?v=SsqYCvJvxQY&ab_channel=INAPolitique).
