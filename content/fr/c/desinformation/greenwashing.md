---
title: Rep√©rer le greenwashing et les conflits d‚Äôint√©r√™ts
date: '2023-02-24'
type: book
weight: 30
tags:
  - √©nergie
  - climat
  - d√©sinformation
---

Quel est le but des climatosceptiques? Que d√©fendent-ils? √âtudes de cas des mod√®les LLaMA et ChatGPT.

<!--more-->

## La d√©sinformation sert √† d√©tourner l‚Äôattention de l‚Äôurgence √©cologique‚Ä¶

Sur Twitter (achet√© par Elon Musk en xxxx), plus de 10 000 comptes climatosceptiques actifs relaient des fausses informations [CNRS](https://lejournal.cnrs.fr/articles/climatosceptiques-sur-twitter-enquete-sur-les-mercenaires-de-lintox).

Le but de la d√©sinformation comme [business](https://www.bfmtv.com/tech/intelligence-artificielle/le-patron-de-l-entreprise-a-l-origine-de-chat-gpt-a-un-peu-peur-de-chat-gpt_AV-202303210270.html) est de d√©tourner l‚Äôattention et influencer les d√©cisions, par exemple dans quoi [investir](https://www.bpifrance.fr/nos-actualites/rencontres-economiques-daix-en-provence-un-regard-sur-le-monde-demain), de quoi [d√©battre](https://www.bfmtv.com/tech/intelligence-artificielle/pour-la-premiere-fois-l-assemblee-nationale-va-debattre-d-un-amendement-redige-par-chat-gpt_AV-202303210310.html), etc. Lorsqu‚Äôelle est toxique et virale, elle g√©n√®re plus de clics (Click Through Rate en anglais) et appelle √† plus de deeptech...

Ainsi, les d√©veloppements d'IA pendant l'automne hiver 2022/2023 - [Galactica 120B](https://huggingface.co/facebook/galactica-120b), ChatGPT3, LLaMA 65B, ChatGPT4 - et la d√©sinformation a permis de d√©tourner l'attention des CEO au [Forum √âconomique Mondial](https://www.reuters.com/technology/davos-2023-ceos-buzz-about-chatgpt-style-ai-world-economic-forum-2023-01-17/) pour investir dans l'armement au profit de HuggingFace, les GAFAMs, NVIDIA, etc.

En mars 2023, TF1 parle de menaces de l'IA sur les emplois, de risques des voitures autonomes... l'√©cologie et la jeunesse ne sont pas mentionn√©s.
Le [MIT](https://www.technologyreview.com/2019/02/14/137426/an-ai-tool-auto-generates-fake-news-bogus-tweets-and-plenty-of-gibberish/) alertait pourtant en 2019 du risque qu'IA une qui √©crit une prose convaincante risquerait de produire en masse de fausses nouvelles, faisant r√©f√©rence √† ChatGPT2. Cela n'a emp√™ch√© les investissments de se multiplier dans la d√©sinformation, la consommation √©nerg√©tique (x1000 en 4 ans) et la g√©n√©ration de fausses nouvelles.

### Ressources pour lutter contre le greenwashing
- Le guide anti greenwashing de [Pour un R√©veil Ecologique](https://pour-un-reveil-ecologique.org/fr/les-entreprises-nous-repondent/#guide-anti-greenwashing)
- L'outil en ligne anti greenwashing de l'[ADEME](https://communication-responsable.ademe.fr/antigreenwashing)

## [Pr√©sentation de LLaMA : un mod√®le de langage fondamental de 65 milliards de param√®tres](https://ai.facebook.com/blog/large-language-model-llama-meta-ai/)
{{< icon name="calendar" pack="fas" >}} F√©v 2023. Le blog de Meta AI / FAIR Paris est une {{<hl>}}perle de greenwashing{{</hl>}}.

Dans le cadre de l'engagement de Meta en faveur de la science ouverte, nous publions aujourd'hui LLaMA (Large Language Model Meta AI), un mod√®le de langage fondamental √† l‚Äô√©tat de l‚Äôart con√ßu pour aider les chercheurs √† faire progresser leurs travaux dans ce sous-domaine de l'IA. {{<hl>}}Des mod√®les <b>plus petits</b> et plus performants tels que LLaMA{{</hl>}} permettent √† d'autres membres de la communaut√© de recherche qui n'ont pas acc√®s √† de grandes quantit√©s d'infrastructures d'√©tudier ces mod√®les, d√©mocratisant davantage l'acc√®s dans ce domaine important et en √©volution rapide.

{{<hl>}}L'entra√Ænement de mod√®les fondamentaux <b>plus petits</b> comme LLaMA est souhaitable{{</hl>}} dans le champ des large language model, car {{<hl>}}√ßa n√©cessite beaucoup <b>moins de puissance de calcul et de ressources</b>{{</hl>}} pour tester de nouvelles approches, valider le travail des autres et explorer de nouveaux cas d'utilisation. Les mod√®les fondamentaux sont entra√Æn√©s sur un vaste ensemble de donn√©es non √©tiquet√©es, ce qui les rend id√©aux pour √™tre ajust√© √† une vari√©t√© de t√¢ches. Nous rendons LLaMA disponible en plusieurs tailles (param√®tres 7B, 13B, 33B et 65B) et partageons √©galement une carte du mod√®le LLaMA qui d√©taille comment nous avons construit le mod√®le conform√©ment √† notre approche des {{<hl>}}<b>pratiques d'IA responsable</b>{{</hl>}}.

{{< figure src="meta-paper-hours-gpu.png" caption="Empreinte carbone de diff√©rents mod√®les entrain√©s dans le m√™me centre de donn√©es, de l'article LLaMA sur [Arxiv](https://arxiv.org/abs/2302.13971) (section 6 Empreinte carbone).">}}

{{< callout warning >}}
<i>L'entra√Ænement de nos mod√®les a consomm√© une quantit√© massive d'√©nergie, responsable de l'√©mission de dioxyde de carbone.</i> (section 6 Empreinte carbone). <i>Nous pr√©voyons de publier √† l'avenir des mod√®les plus grands, entrain√©s sur des corpus plus importants</i> (section 8 Conclusion). [Arxiv](https://arxiv.org/abs/2302.13971).
{{< /callout >}}

{{< callout note >}}
Aucune communication n'est faite sur [le blog](https://ai.facebook.com/blog/large-language-model-llama-meta-ai/) de Meta AI Research, sur les [r√©seaux sociaux](https://www.linkedin.com/posts/yann-lecun_github-facebookresearchllama-inference-activity-7034956639526952960-B1-d?trk=public_profile_like_view) ou sur [Github](https://github.com/facebookresearch/llama/blob/1076b9c51c77ad06e9d7ba8a4c6df775741732 ) concernant l'empreinte carbone record, l'impact environnemental et le financement du mod√®le LLaMA.
{{< /callout >}}

{{<hl>}}Des mod√®les <b>plus petits</b>{{</hl>}} entra√Æn√©s sur plus de jetons - qui sont des morceaux de mots - sont {{<hl>}}<b>plus faciles</b> √† r√©entra√Æner et affiner{{</hl>}} pour des cas d'utilisation potentiels et sp√©cifiques de produits. Nous avons entra√Æn√© LLaMA 65B et LLaMA 33B sur 1,4 trilliard de jetons. Notre {{<hl>}}<b>plus petit</b> mod√®le{{</hl>}}, LLaMA 7B, est form√© sur un trilliard de jetons‚Ä¶

{{< callout note >}}
En r√©alit√© on change d‚Äô√©chelle. Millions, milliards, trilliards... C‚Äôest x1000 en complexit√© en 4 ans.
{{< /callout >}}

Il reste encore des recherches √† faire pour traiter les risques de biais, de commentaires toxiques et d'hallucinations dans les grands mod√®les de langage. Comme d'autres mod√®les, LLaMA partage ces d√©fis... Nous fournissons √©galement dans l'article un ensemble d'√©valuations sur les biais et la toxicit√© du mod√®le pour montrer les limites du mod√®le et pour soutenir la poursuite des recherches dans ce domaine crucial.

{{<hl>}}Pour maintenir l'<b>int√©grit√©</b> et pr√©venir les <b>abus</b>{{</hl>}}, nous publions notre mod√®le sous une licence non commerciale ax√©e sur les cas d'utilisation de la recherche. L'acc√®s au mod√®le sera accord√© au cas par cas aux chercheurs universitaires; ceux affili√©s √† des organisations du gouvernement, de la soci√©t√© civile et du milieu universitaire; et les laboratoires de recherche de l'industrie √† travers le monde...

{{< callout warning >}}
08 mars 2023. [Fuite du mod√®le](https://www.01net.com/actualites/fuite-meta-alternative-chatgpt-meta-partagee-forum.html). Int√©grit√© et pr√©vention des abus? Fausses nouvelles et mod√®le √©conomique?
{{< /callout >}}

## [Consid√©rations √©thiques sur Github](https://github.com/facebookresearch/llama/blob/1076b9c51c77ad06e9d7ba8a4c6df775741732bd/MODEL_CARD.md)
- Organisation d√©veloppant le mod√®le: L'√©quipe FAIR de Meta AI.
- Date du mod√®le: LLaMA a √©t√© entra√Æn√© entre d√©cembre 2022 et f√©vrier 2023.
- Version du mod√®le: Il s'agit de la version 1 du mod√®le.
- Donn√©es: Les donn√©es utilis√©es pour entra√Æner le mod√®le sont collect√©es √† partir de diverses sources, principalement du Web. En tant que tel, il contient un contenu offensant, pr√©judiciable et biais√©. Nous nous attendons √† ce que le mod√®le pr√©sente de tels biais.
- Risques et pr√©judices: Les risques et pr√©judices des grands mod√®les linguistiques incluent la g√©n√©ration de contenu nuisible, offensant ou biais√©. Ces mod√®les sont souvent susceptibles de g√©n√©rer des informations incorrectes. Nous ne nous attendons pas √† ce que notre mod√®le soit une exception √† cet √©gard.
- Cas d'utilisation: LLaMA est un mod√®le fondamental et, en tant que tel, il ne doit pas √™tre utilis√© pour des applications sans une enqu√™te plus approfondie et une att√©nuation des risques. Ces risques et cas d'utilisation potentiellement dangereux incluent, mais sans s'y limiter : la <b>g√©n√©ration de fausses informations</b> et la <b>g√©n√©ration de contenu nuisible, biais√© ou offensant</b>.

### üíß Crise climatique
- 15-02 <b style="color:red;">CNRS</b>. Climatosceptiques: sur Twitter, enqu√™te sur les mercenaires de l‚Äôintox [cnrs.fr](https://lejournal.cnrs.fr/articles/climatosceptiques-sur-twitter-enquete-sur-les-mercenaires-de-lintox) [Le Monde](https://www.lemonde.fr/planete/article/2023/02/13/la-france-fait-face-a-un-fort-regain-de-climatoscepticisme-sur-twitter_6161691_3244.html) @[Audrey Garric](https://twitter.com/audreygarric/status/1625416947729944579?cxt=HHwWhsC-1cSG0o4tAAAA).
- 31-12 (2022) <b style="color:blue;">Emmanuel Macron</b> <i>Qui aurait pu pr√©dire la crise climatique?</i> [archive INA](https://www.youtube.com/watch?v=SsqYCvJvxQY&ab_channel=INAPolitique).

## [Lutter contre le changement climatique avec l'IA](https://arxiv.org/abs/1906.05433)

L'article original est publi√© sur [Arxiv](https://arxiv.org/abs/1906.05433v1) le 10 juin 2019, quatre jours apr√®s l'alerte d'[Emma Strubell](https://arxiv.org/abs/1906.02243) et du [MIT](https://www.technologyreview.com/2019/06/06/239031/training-a-single-ai-model-can-emit-as-much-carbon-as-five-cars-in-their-lifetimes/) en 2019. √âcrit par 22 auteurs dont <b>Demis Hassabis</b>, CEO de <b>Deepmind</b>, et <b>Yoshua Bengio</b>, prix <b>Turing</b> 2019 et parrain du deep learning, il est republi√© le 7 f√©vrier 2022 par l'[Association for Computing Machinery](https://dl.acm.org/doi/10.1145/3485128) (ACM) qui remet le prix Turing. En d√©cembre 2022, alors que Yann Lecun et Elon Musk travaillent sur des mod√®les avec des milliards de param√®tres (1000 fois l'alerte du [MIT](https://www.technologyreview.com/2019/06/06/239031/training-a-single-ai-model-can-emit-as-much-carbon-as-five-cars-in-their-lifetimes/) de 2019), un workshop est organis√© par climatechange.ai √† [NeurIPS 2022](https://www.climatechange.ai/events/neurips2022) et inclut 19 auteurs de <b style='color:blue;'>NVIDIA</b> qui tire profit de l'explosion de la complexit√© des mod√®les.

Les projecteurs durant ces ann√©es √©taient braqu√©s sur les parrains du <i>deep learning</i>, au profit des GAFAMs et de NVIDIA, leader mondial du calcul en intelligence artificielle. 

## Recherche et cadeaux en IA

Les cadeaux influencent la recherche en IA pour continuer d'entrainer des mod√®les toujours plus complexes, au profit des <b style='color:blue;'>GAFAM</b> et <b style='color:blue;'>NVIDIA</b>.
L'article [Seize t√™tes valent-elles vraiment mieux qu'une?](https://arxiv.org/abs/1905.10650) soumis sur [Arxiv](https://arxiv.org/abs/1905.10650) le 25 mai 2019 et accept√© √† NeurIPS 2019 a √©t√© co-√©crit par un alumni de l'√âcole Polytechnique (X13) qui √©crit dans les remerciements <i> Nous sommes particuli√®rement reconnaissants √† <b>Thomas Wolf</b> de <b style='color:blue;'>Hugging Face</b>, dont les efforts de reproduction ind√©pendants nous ont permis de trouver et de corriger un bug... Cette recherche a √©t√© financ√©e en partie par un cadeau de <b style='color:blue;'>Facebook</b>.</i>

## En juin 2022, ENGIE premier client

<i><b style='color:blue;'>Deep Mind</b> a appliqu√© des algorithmes de ML pour pr√©dire l'√©nergie √©olienne. <b style='color:blue;'>Google</b> a annonc√© que cet algorithme pouvait pr√©dire la production d'√©nergie √©olienne trente-six heures √† l'avance. En juin, <b>ENGIE</b> (une soci√©t√© fran√ßaise) a √©t√© annonc√©e comme le premier client du projet</i>. [Towards Data Science](https://towardsdatascience.com/machine-learning-to-tackle-climate-change-7911e004c3a2) et [Bloomberg](https://www.bloomberg.com/news/articles/2022-06-01/google-and-france-s-engie-team-up-to-accelerate-wind-power#xj4y7vzkg).

Le 23-24 novembre 2022, pendant que Patrick Pouyanne, PDG de <b>Total Energies</b>, est auditionn√© √† l'Assembl√©e nationale au sein de la [commission d'enqu√™te visant √† √©tablir les raisons de la perte de souverainet√© et d'ind√©pendance √©nerg√©tique de la France](https://www.assemblee-nationale.fr/dyn/16/organes/autres-commissions/commissions-enquete/ce-independance-energetique), <b>ENGIE</b> et <b style='color:blue;'>Google</b> concluent un contrat de 100 MW, d'une dur√©e de 12 ans, pour fournir √† <b style='color:blue;'>Google</b> plus de 5 TWh d'√©nergie verte provenant du projet Moray West, un parc √©olien offshore de pr√®s de 900 MW, dont la mise en service est pr√©vue en 2025. [Engie.com](https://newsroom.engie.com/actualites/engie-et-google-concluent-un-contrat-dachat-delectricite-renouvelable-cppa-grace-au-developpement-docean-winds-dans-leolien-offshore-e469-ff316.html). L'<b style="color:red;">Europe</b> accuse les √âtats-Unis de profiter de la guerre. [Politico.eu](https://www.politico.eu/article/vladimir-putin-war-europe-ukraine-gas-inflation-reduction-act-ira-joe-biden-rift-west-eu-accuses-us-of-profiting-from-war/).

{{< callout warning >}}
Le 25-26 juin 2022, <b>Total</b>, <b>EDF</b>, et <b>ENGIE</b> alertaient de la menace des prix sur la coh√©sion. [JDD](https://www.lejdd.fr/societe/tribune-le-prix-de-lenergie-menace-notre-cohesion-par-les-patrons-dengie-edf-et-totalenergies-9401), appellant les Fran√ßais √† une sobri√©t√© d'urgence [face √† la flamb√©e des prix de l'√©nergie](https://www.bfmtv.com/economie/total-edf-et-engie-appellent-les-francais-a-une-sobriete-d-urgence-face-a-la-flambee-des-prix-de-l-energie_VN-202206260112.html) et √† r√©duire ["imm√©diatement"](https://www.bfmtv.com/economie/entreprises/energie/total-energies-edf-et-engie-appellent-a-reduire-immediatement-la-consommation-d-energie_AD-202206260081.html) la consommation d'√©nergie.
{{< /callout >}}

