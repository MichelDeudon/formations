---
title: Repérer le greenwashing et les conflits d’intérêts
date: '2023-02-24'
type: book
weight: 30
tags:
  - intelligence artificielle
  - énergie
  - climat
  - désinformation
  - environnement et société
---

Quel est le but des climatosceptiques? Que défendent-ils? Pourquoi ChatGPT représente une source de désinformation? Études de cas des modèles LLaMA et ChatGPT.

<!--more-->

## La désinformation sert à détourner l’attention de l’urgence écologique

<i>[Qui aurait pu prédire la crise climatique?](https://www.youtube.com/watch?v=SsqYCvJvxQY&ab_channel=INAPolitique)</i> demandait <b>Emmanuel Macron</b> fin 2022.
Six semaines plus tard, pendant le [record de sécheresse](https://meteofrance.com/actualites-et-dossiers/actualites/climat/secheresse-32-jours-sans-pluie-en-france-record-battu) en France, le [CNRS](https://lejournal.cnrs.fr/articles/climatosceptiques-sur-twitter-enquete-sur-les-mercenaires-de-lintox), [ISCPIF](https://iscpif.fr/climatoscope/?p=72), [Citizen4science](https://citizen4science.org/climatoscope-du-cnrs-les-nouveaux-fronts-du-denialisme-et-du-climato-scepticisme/), [le Monde](https://www.lemonde.fr/planete/article/2023/02/13/la-france-fait-face-a-un-fort-regain-de-climatoscepticisme-sur-twitter_6161691_3244.html) et la journaliste [Audrey Garric](https://twitter.com/audreygarric/status/1625416947729944579?cxt=HHwWhsC-1cSG0o4tAAAA) alertent d'une montée du climatosceptisme sur <b>Twitter</b> (acheté par Elon Musk en 2022). Une importante communauté s’est structurée à partir de l’été 2022. Plus de 10 000 comptes actifs relaient des fausses informations et attaquent le [GIEC](https://www.ecologie.gouv.fr/publication-du-6e-rapport-synthese-du-giec), à coups de milliers de tweets quotidiens.

{{< figure src="desinfo/FakeNews - ChatGPT3.jpg" caption="Février 2023 (ChatGPT3) Capture d’écran d’un étudiant en licence MIASHS. Février 2019 (ChatGPT2) Une IA qui écrit une prose convaincante risque de produire en masse de fausses nouvelles. [MIT Technology Review](https://www.technologyreview.com/2019/02/14/137426/an-ai-tool-auto-generates-fake-news-bogus-tweets-and-plenty-of-gibberish/) (Cela n'a pas empêché les investissments de se multiplier dans la désinformation). Mars 2023 (ChatGPT4) Explosion de la désinformation. [BFM Business](https://www.bfmtv.com/tech/intelligence-artificielle/le-patron-de-l-entreprise-a-l-origine-de-chat-gpt-a-un-peu-peur-de-chat-gpt_AV-202303210270.html).">}}

Le but de la désinformation comme [business](https://www.bfmtv.com/tech/intelligence-artificielle/le-patron-de-l-entreprise-a-l-origine-de-chat-gpt-a-un-peu-peur-de-chat-gpt_AV-202303210270.html) est de détourner l’attention et influencer les décisions, par exemple dans quoi [investir](https://www.bpifrance.fr/nos-actualites/rencontres-economiques-daix-en-provence-un-regard-sur-le-monde-demain), de quoi [débattre](https://www.bfmtv.com/tech/intelligence-artificielle/pour-la-premiere-fois-l-assemblee-nationale-va-debattre-d-un-amendement-redige-par-chat-gpt_AV-202303210310.html), etc. Lorsqu’elle est toxique et virale, elle génère plus de clics (Click Through Rate en anglais) et appelle à plus de deeptech...

{{< figure src="desinfo/mafia-desinformation.png">}}

Ainsi, les développements d'IA pendant l'automne hiver 2022/2023 - [Galactica 120B](https://huggingface.co/facebook/galactica-120b), ChatGPT3, LLaMA 65B, ChatGPT4 - et la désinformation a permis de détourner l'attention des CEO au [Forum Économique Mondial](https://www.reuters.com/technology/davos-2023-ceos-buzz-about-chatgpt-style-ai-world-economic-forum-2023-01-17/) pour investir dans l'armement plutôt que la résilience et le changement climatique.

En mars 2023, <b>TF1</b> parlait d'[IA et de guerre](https://www.tf1info.fr/player/debdff38-d5d9-4685-84ef-7959f4cdd39e/), de menaces de l'IA sur [les emplois, les voitures autonomes](https://www.tf1info.fr/sciences-et-innovation/interview-destruction-d-emplois-desinformation-faut-il-mettre-en-pause-les-recherches-sur-l-ia-intelligence-artificielle-comme-chatgpt-comme-le-demande-une-tribune-2252595.html)... l'écologie et la jeunesse ne sont jamais mentionnés. Le documentaire et l'article de <b>TF1</b> citent l'une des plus grandes banques américaines, <b>Goldman Sachs</b>, et <b>Bellingcat</b>, dont le modèle économique est construit sur la désinformation, comme source d'information.

En réalité, en projetant les modèles sur un axe (métrique) sans prendre en compte les ressources, énergie, coûts réels, la recherche en IA est devenue une course pour consommer et polluer plus. De [HighRes-net](https://github.com/ServiceNow/HighRes-net) (2019) à [TR-MISR](https://paperswithcode.com/sota/multi-frame-super-resolution-on-proba-v?p=highres-net-recursive-fusion-for-multi-frame) (2022), la métrique d'IA s’est ainsi améliorée d’un peu de moins de 2%, mais avec une complexité quadratique au lieu de logarithmique, et un temps pour entraîner une fois qui passe de 9h à 60h sur une carte <b>NVIDIA</b> Tesla V100. TR-MISR utilise le modèle [Transformer](https://arxiv.org/abs/1706.03762), que l’on retrouve dans BERT, ChatGPT et LLaMA. Ce n’est donc pas plus d’IA, au service de l’IA, qu’il faut (c’est le but de la désinformation!).
Si demain <b>Twitter</b> était uniquement constitué de bots, faux profils et climatosceptiques, quelle serait sa valeur?

### Ressources pour lutter contre le greenwashing
- Le guide anti greenwashing de [Pour un Réveil Ecologique](https://pour-un-reveil-ecologique.org/fr/les-entreprises-nous-repondent/#guide-anti-greenwashing)
- L'outil en ligne anti greenwashing de l'[ADEME](https://communication-responsable.ademe.fr/antigreenwashing)

## Cas pratiques

### A. [LLaMA](https://ai.facebook.com/blog/large-language-model-llama-meta-ai/)
{{< icon name="calendar" pack="fas" >}} Fév 2023. Le blog de <b>Meta AI / FAIR Paris</b> est une {{<hl>}}perle de greenwashing{{</hl>}}.

Dans le cadre de l'engagement de Meta en faveur de la science ouverte, nous publions aujourd'hui LLaMA (Large Language Model Meta AI), un modèle de langage fondamental à l’état de l’art conçu pour aider les chercheurs à faire progresser leurs travaux dans ce sous-domaine de l'IA. {{<hl>}}Des modèles <b>plus petits</b> et plus performants tels que LLaMA{{</hl>}} permettent à d'autres membres de la communauté de recherche qui n'ont pas accès à de grandes quantités d'infrastructures d'étudier ces modèles, démocratisant davantage l'accès dans ce domaine important et en évolution rapide.

{{<hl>}}L'entraînement de modèles fondamentaux <b>plus petits</b> comme LLaMA est souhaitable{{</hl>}} dans le champ des large language model, car {{<hl>}}ça nécessite beaucoup <b>moins de puissance de calcul et de ressources</b>{{</hl>}} pour tester de nouvelles approches, valider le travail des autres et explorer de nouveaux cas d'utilisation. Les modèles fondamentaux sont entraînés sur un vaste ensemble de données non étiquetées, ce qui les rend idéaux pour être ajusté à une variété de tâches. Nous rendons LLaMA disponible en plusieurs tailles (paramètres 7B, 13B, 33B et 65B) et partageons également une carte du modèle LLaMA qui détaille comment nous avons construit le modèle conformément à notre approche des {{<hl>}}<b>pratiques d'IA responsable</b>{{</hl>}}.

{{< callout note >}}
LLaMA a été entraîné entre décembre 2022 et février 2023 mais aucune communication n'est faite sur [le blog](https://ai.facebook.com/blog/large-language-model-llama-meta-ai/) de Meta AI Research, sur les [réseaux sociaux](https://www.linkedin.com/posts/yann-lecun_github-facebookresearchllama-inference-activity-7034956639526952960-B1-d?trk=public_profile_like_view) ou sur [Github](https://github.com/facebookresearch/llama/blob/1076b9c51c77ad06e9d7ba8a4c6df775741732 ) concernant l'empreinte carbone record, l'impact environnemental et le financement de la version 1.
{{< /callout >}}

{{<hl>}}Des modèles <b>plus petits</b>{{</hl>}} entraînés sur plus de jetons - qui sont des morceaux de mots - sont {{<hl>}}<b>plus faciles</b> à réentraîner et affiner{{</hl>}} pour des cas d'utilisation potentiels et spécifiques de produits. Nous avons entraîné LLaMA 65B et LLaMA 33B sur 1,4 trilliard de jetons. Notre {{<hl>}}<b>plus petit</b> modèle{{</hl>}}, LLaMA 7B, est formé sur un trilliard de jetons…

{{< callout note >}}
En réalité on change d’échelle. Millions, milliards, trilliards... C’est x1000 en complexité en 4 ans.
{{< /callout >}}

Il reste encore des recherches à faire pour traiter les risques de biais, de commentaires toxiques et d'hallucinations dans les grands modèles de langage. Comme d'autres modèles, LLaMA partage ces défis... Nous fournissons également dans l'article un ensemble d'évaluations sur les biais et la toxicité du modèle pour montrer les limites du modèle et pour soutenir la poursuite des recherches dans ce domaine crucial.

{{<hl>}}Pour maintenir l'<b>intégrité</b> et prévenir les <b>abus</b>{{</hl>}}, nous publions notre modèle sous une licence non commerciale axée sur les cas d'utilisation de la recherche. L'accès au modèle sera accordé au cas par cas aux chercheurs universitaires; ceux affiliés à des organisations du gouvernement, de la société civile et du milieu universitaire; et les laboratoires de recherche de l'industrie à travers le monde...

{{< callout warning >}}
08 mars 2023. [Fuite du modèle](https://www.01net.com/actualites/fuite-meta-alternative-chatgpt-meta-partagee-forum.html). Les risques et cas d'utilisation potentiellement dangereux incluent, mais sans s'y limiter : la <b>génération de fausses informations</b> et la <b>génération de contenu nuisible, biaisé ou offensant</b>. [Github](https://github.com/facebookresearch/llama/blob/1076b9c51c77ad06e9d7ba8a4c6df775741732bd/MODEL_CARD.md). Quel est le modèle économique de Facebook?
{{< /callout >}}

### B. [Lutter contre le changement climatique avec l'IA](https://arxiv.org/abs/1906.05433)

L'article original est publié sur [Arxiv](https://arxiv.org/abs/1906.05433v1) en juin 2019, quatre jours après l'alerte d'[Emma Strubell](https://arxiv.org/abs/1906.02243) et du [MIT](https://www.technologyreview.com/2019/06/06/239031/training-a-single-ai-model-can-emit-as-much-carbon-as-five-cars-in-their-lifetimes/). Écrit par 22 auteurs dont <b>Demis Hassabis</b>, CEO de <b>Deepmind</b>, et <b>Yoshua Bengio</b>, parrain du <i>deep learning</i>, il est republié en février 2022 par l'[Association for Computing Machinery](https://dl.acm.org/doi/10.1145/3485128) (ACM), le lobbie américain qui a remis en 2019 le prix Turing à <b>Yoshua Bengio</b>, <b>Geoffrey Hinton</b> (<b>Google</b>) et <b>Yann Le Cun</b> (<b>Facebook</b>).

{{< callout note >}}
En octobre 2019, <b>Laure Delisle</b> et <b>Michel Deudon</b> ont été licencié de la startup <b>Element AI</b>, AI for Good de <b>Yoshua Bengio</b>'s, licencement économique suivant [un tour de table auprès d'investisseurs](https://www.cdpq.com/en/news/pressreleases/element-ai-raises-cad-200m-us-1514m-series-b-round-to-transform-commercial) dont <b>McKinsey & Company</b>. Trois ans plus tard, <b>Manon Gruaz</b> a donné une conférence [CTRL+ALT+Dépression](https://www.youtube.com/watch?v=MN3D0uLEERU&ab_channel=GDGFrance) pointant des problèmes dans la startup <b>Element AI</b>.
{{< /callout >}}

En décembre 2022, alors que <b>Yann Lecun</b> travaille sur des modèles avec des milliards de paramètres, un workshop est organisé par climatechange.ai à [NeurIPS 2022](https://www.climatechange.ai/events/neurips2022) et inclut 19 auteurs de <b>NVIDIA</b>, leader mondial du calcul en intelligence artificielle, qui tire profit de l'explosion de la complexité des modèles et de la désinformation.

### C. Recherche et cadeaux en IA

Les projecteurs sur les parrains du <i>deep learning</i>, mais également des cadeaux et de la corruption ont influencé la recherche en IA pour continuer d'entrainer des modèles toujours plus complexes, au profit des <b>GAFAM</b> et <b>NVIDIA</b>.
L'article [Seize têtes valent-elles vraiment mieux qu'une?](https://arxiv.org/abs/1905.10650) soumis sur [Arxiv](https://arxiv.org/abs/1905.10650) le 25 mai 2019 et accepté à NeurIPS 2019 a été co-écrit par un polytechnicien (X13) qui écrit dans les remerciements <i> Nous sommes particulièrement reconnaissants à <b>Thomas Wolf</b> de <b>Hugging Face</b>, dont les efforts de reproduction indépendants nous ont permis de trouver et de corriger un bug... Cette recherche a été financée en partie par un cadeau de <b>Facebook</b>.</i>

### D. [ENGIE-Google](https://www.bloomberg.com/news/articles/2022-06-01/google-and-france-s-engie-team-up-to-accelerate-wind-power#xj4y7vzkg).

<i><b>Deep Mind</b> a appliqué des algorithmes de ML pour prédire l'énergie éolienne. <b>Google</b> a annoncé que cet algorithme pouvait prédire la production d'énergie éolienne trente-six heures à l'avance. En juin [2022], <b>ENGIE</b> (une société française) a été annoncée comme le premier client du projet</i> sur [Towards Data Science](https://towardsdatascience.com/machine-learning-to-tackle-climate-change-7911e004c3a2) et [Bloomberg](https://www.bloomberg.com/news/articles/2022-06-01/google-and-france-s-engie-team-up-to-accelerate-wind-power#xj4y7vzkg).

{{< callout warning >}}
Le 25-26 juin 2022, <b>Total</b>, <b>EDF</b>, et <b>ENGIE</b> alertaient de la [menace des prix sur la cohésion](https://www.lejdd.fr/societe/tribune-le-prix-de-lenergie-menace-notre-cohesion-par-les-patrons-dengie-edf-et-totalenergies-9401), appellant les Français à une sobriété d'urgence [face à la flambée des prix de l'énergie](https://www.bfmtv.com/economie/total-edf-et-engie-appellent-les-francais-a-une-sobriete-d-urgence-face-a-la-flambee-des-prix-de-l-energie_VN-202206260112.html) et à réduire ["immédiatement"](https://www.bfmtv.com/economie/entreprises/energie/total-energies-edf-et-engie-appellent-a-reduire-immediatement-la-consommation-d-energie_AD-202206260081.html) la consommation d'énergie.
{{< /callout >}}

{{< callout warning >}}
Le 5 septembre 2022, Macron appelle à la <i>sobriété individuelle</i>. <i>"Chacun a son rôle à jouer (...) la meilleure énergie est celle qu’on ne consomme pas"</i>. L’objectif est <i>"d’économiser 10 % de ce que nous consommons actuellement"</i>. [Conférence de presse à l'Elysee](https://www.youtube.com/watch?v=XjC1NqzyGkc&ab_channel=%C3%89lys%C3%A9e). [Plan sobriété ecologie.gouv.fr](https://www.ecologie.gouv.fr/plan-sobriete-acte-2-mobilisation-se-poursuit).
{{< /callout >}}

Le 23-24 novembre 2022, pendant que <b>Patrick Pouyanne</b>, PDG de <b>Total Energies</b>, est auditionné à l'<b>Assemblée nationale</b> au sein de la [commission d'enquête visant à établir les raisons de la perte de souveraineté et d'indépendance énergétique de la France](https://www.assemblee-nationale.fr/dyn/16/organes/autres-commissions/commissions-enquete/ce-independance-energetique), <b>ENGIE</b> et <b>Google</b> concluent un contrat de 100 MW, d'une durée de 12 ans, pour fournir à <b>Google</b> [plus de 5 TWh d'énergie verte provenant du projet Moray West](https://newsroom.engie.com/actualites/engie-et-google-concluent-un-contrat-dachat-delectricite-renouvelable-cppa-grace-au-developpement-docean-winds-dans-leolien-offshore-e469-ff316.html), un parc éolien offshore de près de 900 MW, dont la mise en service est prévue en 2025. [L'Europe accuse les États-Unis de profiter de la guerre](https://www.politico.eu/article/vladimir-putin-war-europe-ukraine-gas-inflation-reduction-act-ira-joe-biden-rift-west-eu-accuses-us-of-profiting-from-war/).

En mars 2023, la [loi relative à l'accélération de la production des énergies renouvelables](https://www.ecologie.gouv.fr/publication-loi-relative-lacceleration-des-energies-renouvelables) énonce des objectifs qui semblent en désaccord avec la stratégie d'<b>ENGIE</b> - préserver le pouvoir d’achat des Français et la compétitivité des entreprises, défendre l’indépendance industrielle, énergétique et politique de la France et lutter contre le dérèglement climatique.