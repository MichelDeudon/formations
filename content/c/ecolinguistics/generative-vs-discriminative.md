---
title: Apprentissage génératif vs discriminatif
date: '2021-01-01'
type: book
weight: 70
---

Créer pour comprendre.

<!--more-->

{{< icon name="clock" pack="fas" >}} 1h20 introductory course

> <i> Ce que je ne peux pas créer, je ne comprends pas </i> - Richard Feynman.

## From Naive Bayes

xyz

## To latent variables and models

Intro PGM

## Modèles de Mixtures Gaussiennes (GMM)

xyz

**Theory:** Probability review. Bayesian learning.

## Modèles de Markov Cachés (HMM)

{{< youtube cRcKueydDkY>}}

**Application**: Melody harmonisation. Ableton. Music.

## Allocation de Dirichlet Latente (LDA)

xyz

## Encodeurs Automatiques Variationnels (VAE)

Les VAE peuvent être utilisés pour apprendre des représensations de phrases qui séparent le style de la sémantique, pour pouvoir mesurer des similarités, par exemple entre des questions.

{{< figure src="linguistics/img7.jpg" caption="Apprendre à répéter, reformuler.  Visualisation des représentations apprises après réduction de dimension avec l'ACP.">}}

**Summary** (models, hypothesis, limits, link with information theory, probabilities, algebra)

## Reference

> Francis Bach. [Introduction to Probabilistic Graphical Models](https://www.di.ens.fr/~fbach/courses/fall2018/). 2018.

> Michel Deudon. [Learning semantic similarity in a continuous space](https://proceedings.neurips.cc/paper/2018/hash/97e8527feaf77a97fc38f34216141515-Abstract.html). Advances in neural information processing systems. vol 31. 2018.
